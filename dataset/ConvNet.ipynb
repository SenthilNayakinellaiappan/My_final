{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, train=True):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        if train:\n",
    "            image_path = path + \"train/\"\n",
    "            names = csv.reader(open(path + \"labels/training/filenames.csv\", 'r'))\n",
    "            landmarks = csv.reader(open(path + \"labels/training/landmarks.csv\", 'r'))\n",
    "        else:\n",
    "            image_path = path + \"test/\"\n",
    "            names = csv.reader(open(path + \"labels/test/filenames.csv\", 'r'))\n",
    "            landmarks = csv.reader(open(path + \"labels/test/landmarks.csv\", 'r'))\n",
    "        \n",
    "        for landmark_each_image in landmarks:\n",
    "            coordinate_list = []\n",
    "            for coordinate in landmark_each_image:\n",
    "                coordinate_list.append(float(coordinate))\n",
    "            self.labels.append(torch.Tensor(coordinate_list))\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            origin_image = cv.imread(image_path + name[0], cv.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            target_height = 512\n",
    "            target_width = 256\n",
    "            image = np.zeros((target_height, target_width), np.uint8)\n",
    "            cv.resize(origin_image, (target_width, target_height), image)\n",
    "            \n",
    "            image = np.reshape(image, (1, image.shape[0], image.shape[1]))\n",
    "            image_tensor = torch.from_numpy(image).float()\n",
    "            \n",
    "            self.images.append(image_tensor)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches(training):  121\n",
      "number of batches(testing):  32\n"
     ]
    }
   ],
   "source": [
    "# initialize the train and test data loader\n",
    "\n",
    "train_data = BoostNetDataset(\"\", train=True)\n",
    "test_data = BoostNetDataset(\"\", train=False)\n",
    "\n",
    "batch = 4\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "print(\"number of batches(training): \", len(train_loader))\n",
    "print(\"number of batches(testing): \",len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 16 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 136)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        \n",
    "        x = x.view(-1, 32 * 16 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "# net = torch.load('/disk1/jklu/models/shallow.pth')\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "#lr_func = lambda epoch: epoch * 1\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func)\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.99)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute loss\n",
    "\n",
    "def compute_loss(net, data_loader):\n",
    "    loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loader, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs.float(), labels.float()) \n",
    "            loss_sum += loss.item()\n",
    "            \n",
    "    return loss_sum / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "epoch_num = 100\n",
    "\n",
    "loss1 = []\n",
    "loss2 = []\n",
    "\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "   \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "                \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()    \n",
    "    \n",
    "    train_loss = compute_loss(net, train_loader)\n",
    "    loss1.append(train_loss)\n",
    "\n",
    "    test_loss = compute_loss(net, test_loader)\n",
    "    loss2.append(test_loss)\n",
    "    print(\"epoch number\", epoch+1, \"train_loss\", train_loss, \"test_loss\", test_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = range(1, epoch_num+1)\n",
    "\n",
    "plt.plot(x, loss1, label=\"training loss\")\n",
    "plt.plot(x, loss2, label=\"testing loss\")\n",
    "plt.xlabel(\"epoch number\")\n",
    "#plt.xticks(np.linspace(1,epoch_num,epoch_num))\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"loss graph\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"./coordinate-regression-loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'shallow.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVimshow2pltimshow(cv_img):\n",
    "    \"\"\"\n",
    "    cv_img: [3, height, width], BGR, numpy array, int(0-255)\n",
    "    \"\"\"\n",
    "    b,g,r = cv.split(cv_img)  \n",
    "    plt_img = cv.merge([r,g,b]).astype(np.int)\n",
    "    return plt_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize result\n",
    "# note: opencv will take image as BGR but plt.imshow will take as RGB. \n",
    "# plt.show need int for 0-255 scale or float for 0-1 scale at each pixel\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "batch, channel, height, width = images.shape\n",
    "# note: images.shape = (batch, channel, width, height)\n",
    "\n",
    "ret = net(images.to(device))\n",
    "\n",
    "batch_img = np.zeros((height, width * batch, 3), np.int)\n",
    "\n",
    "for i in range(batch):\n",
    "    sample = images[i].numpy().squeeze(0)\n",
    "    sample_BGR = cv.cvtColor(sample, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    label = labels[i]\n",
    "    predict = ret[i]\n",
    "\n",
    "    point_num = len(label) // 2\n",
    "    for j in range(point_num):\n",
    "        cv.circle(sample_BGR, (int(label[j] * width), int(label[j + point_num]* height)), 2, (255, 255, 0))\n",
    "        cv.circle(sample_BGR, (int(predict[j] * width), int(predict[j + point_num]* height)), 2, (0, 0, 255))\n",
    "        \n",
    "    plt_img = CVimshow2pltimshow(sample_BGR)\n",
    "    batch_img[:, i * width:(i+1) * width, :] = plt_img\n",
    "    \n",
    "    \n",
    "plt.imshow(batch_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
